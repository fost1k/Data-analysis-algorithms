{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import xgboost as xgb, lightgbm as lgbm, catboost as catb\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('assignment_2_train.csv', sep=',')\n",
    "test_data = pd.read_csv('assignment_2_test.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2987003</td>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>W</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987004</td>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>H</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        2987000        0          86400            68.5         W  13926   \n",
       "1        2987001        0          86401            29.0         W   2755   \n",
       "2        2987002        0          86469            59.0         W   4663   \n",
       "3        2987003        0          86499            50.0         W  18132   \n",
       "4        2987004        0          86506            50.0         H   4497   \n",
       "\n",
       "   card2  card3       card4  card5  ... V330  V331  V332  V333  V334 V335  \\\n",
       "0    NaN  150.0    discover  142.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "1  404.0  150.0  mastercard  102.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "2  490.0  150.0        visa  166.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "3  567.0  150.0  mastercard  117.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "4  514.0  150.0  mastercard  102.0  ...  0.0   0.0   0.0   0.0   0.0  0.0   \n",
       "\n",
       "  V336  V337  V338  V339  \n",
       "0  NaN   NaN   NaN   NaN  \n",
       "1  NaN   NaN   NaN   NaN  \n",
       "2  NaN   NaN   NaN   NaN  \n",
       "3  NaN   NaN   NaN   NaN  \n",
       "4  0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 394 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((180000, 394), (100001, 394))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionID          0\n",
       "isFraud                0\n",
       "TransactionDT          0\n",
       "TransactionAmt         0\n",
       "ProductCD              0\n",
       "                   ...  \n",
       "V335              132004\n",
       "V336              132004\n",
       "V337              132004\n",
       "V338              132004\n",
       "V339              132004\n",
       "Length: 394, dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'isFraud'\n",
    "#разбиваем фичи на типы\n",
    "base_features = train_data.columns.drop([target]).tolist()\n",
    "cat_features = train_data.select_dtypes(include='object').columns.tolist()\n",
    "num_features = train_data.columns.drop([target] + cat_features).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_num_features(X):\n",
    "    for feature in num_features:\n",
    "        X.loc[(X[feature].isna()) | \\\n",
    "               (X[feature] > X[feature].quantile(.975)) | \\\n",
    "               (X[feature] < X[feature].quantile(.025)), feature] = X[feature].median()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = missing_num_features(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data[num_features]\n",
    "y = train_data[target]\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение без категориальных переменных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 3000,\n",
    "    \"reg_lambda\": 50,\n",
    "    \"max_depth\": 20,\n",
    "    \"gamma\": 5,\n",
    "    \"nthread\": 4,\n",
    "    \"seed\": 29\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kosfo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.68706\tvalidation_1-auc:0.68248\n",
      "[10]\tvalidation_0-auc:0.82771\tvalidation_1-auc:0.81992\n",
      "[20]\tvalidation_0-auc:0.84399\tvalidation_1-auc:0.83529\n",
      "[30]\tvalidation_0-auc:0.87790\tvalidation_1-auc:0.87151\n",
      "[40]\tvalidation_0-auc:0.89490\tvalidation_1-auc:0.88611\n",
      "[50]\tvalidation_0-auc:0.90561\tvalidation_1-auc:0.89630\n",
      "[60]\tvalidation_0-auc:0.91465\tvalidation_1-auc:0.90256\n",
      "[70]\tvalidation_0-auc:0.92179\tvalidation_1-auc:0.90787\n",
      "[80]\tvalidation_0-auc:0.92654\tvalidation_1-auc:0.91121\n",
      "[90]\tvalidation_0-auc:0.93149\tvalidation_1-auc:0.91465\n",
      "[100]\tvalidation_0-auc:0.93463\tvalidation_1-auc:0.91662\n",
      "[110]\tvalidation_0-auc:0.93709\tvalidation_1-auc:0.91815\n",
      "[120]\tvalidation_0-auc:0.93875\tvalidation_1-auc:0.91965\n",
      "[130]\tvalidation_0-auc:0.94072\tvalidation_1-auc:0.92080\n",
      "[140]\tvalidation_0-auc:0.94148\tvalidation_1-auc:0.92122\n",
      "[150]\tvalidation_0-auc:0.94148\tvalidation_1-auc:0.92122\n",
      "[154]\tvalidation_0-auc:0.94148\tvalidation_1-auc:0.92122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='auc',\n",
       "              gamma=5, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=10, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=1000, n_jobs=4, nthread=4,\n",
       "              num_parallel_tree=1, random_state=29, reg_alpha=0, reg_lambda=50,\n",
       "              scale_pos_weight=1, seed=29, subsample=1, tree_method='exact',\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model_without_cat = xgb.XGBClassifier(**params_xgb)\n",
    "xgb_model_without_cat.fit(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    early_stopping_rounds=20,\n",
    "    eval_metric=\"auc\",\n",
    "    verbose=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgbm = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 3000,\n",
    "    \"n_jobs\": 10,\n",
    "    \"max_depth\": 30,\n",
    "    \"seed\": 29\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttraining's auc: 0.882063\tvalid_1's auc: 0.87838\n",
      "[20]\ttraining's auc: 0.902398\tvalid_1's auc: 0.892691\n",
      "[30]\ttraining's auc: 0.916838\tvalid_1's auc: 0.901541\n",
      "[40]\ttraining's auc: 0.929146\tvalid_1's auc: 0.908444\n",
      "[50]\ttraining's auc: 0.939271\tvalid_1's auc: 0.915171\n",
      "[60]\ttraining's auc: 0.945553\tvalid_1's auc: 0.917893\n",
      "[70]\ttraining's auc: 0.950606\tvalid_1's auc: 0.919442\n",
      "[80]\ttraining's auc: 0.95599\tvalid_1's auc: 0.922586\n",
      "[90]\ttraining's auc: 0.959541\tvalid_1's auc: 0.924521\n",
      "[100]\ttraining's auc: 0.961686\tvalid_1's auc: 0.925701\n",
      "[110]\ttraining's auc: 0.964265\tvalid_1's auc: 0.927433\n",
      "[120]\ttraining's auc: 0.967162\tvalid_1's auc: 0.928697\n",
      "[130]\ttraining's auc: 0.969394\tvalid_1's auc: 0.929928\n",
      "[140]\ttraining's auc: 0.972042\tvalid_1's auc: 0.93097\n",
      "[150]\ttraining's auc: 0.974008\tvalid_1's auc: 0.931746\n",
      "[160]\ttraining's auc: 0.975613\tvalid_1's auc: 0.93352\n",
      "[170]\ttraining's auc: 0.976959\tvalid_1's auc: 0.934537\n",
      "[180]\ttraining's auc: 0.978842\tvalid_1's auc: 0.934791\n",
      "[190]\ttraining's auc: 0.980114\tvalid_1's auc: 0.936234\n",
      "[200]\ttraining's auc: 0.98066\tvalid_1's auc: 0.936632\n",
      "[210]\ttraining's auc: 0.981291\tvalid_1's auc: 0.937608\n",
      "[220]\ttraining's auc: 0.982702\tvalid_1's auc: 0.938722\n",
      "[230]\ttraining's auc: 0.983715\tvalid_1's auc: 0.940224\n",
      "[240]\ttraining's auc: 0.984944\tvalid_1's auc: 0.940807\n",
      "[250]\ttraining's auc: 0.986111\tvalid_1's auc: 0.941492\n",
      "[260]\ttraining's auc: 0.987238\tvalid_1's auc: 0.94223\n",
      "[270]\ttraining's auc: 0.988544\tvalid_1's auc: 0.942794\n",
      "[280]\ttraining's auc: 0.989139\tvalid_1's auc: 0.942773\n",
      "[290]\ttraining's auc: 0.989835\tvalid_1's auc: 0.943391\n",
      "[300]\ttraining's auc: 0.990153\tvalid_1's auc: 0.944013\n",
      "[310]\ttraining's auc: 0.990796\tvalid_1's auc: 0.944676\n",
      "[320]\ttraining's auc: 0.991179\tvalid_1's auc: 0.944875\n",
      "[330]\ttraining's auc: 0.991648\tvalid_1's auc: 0.9453\n",
      "[340]\ttraining's auc: 0.991893\tvalid_1's auc: 0.945257\n",
      "[350]\ttraining's auc: 0.992628\tvalid_1's auc: 0.946221\n",
      "[360]\ttraining's auc: 0.993215\tvalid_1's auc: 0.947031\n",
      "[370]\ttraining's auc: 0.993534\tvalid_1's auc: 0.947172\n",
      "[380]\ttraining's auc: 0.993911\tvalid_1's auc: 0.947732\n",
      "[390]\ttraining's auc: 0.994619\tvalid_1's auc: 0.947837\n",
      "[400]\ttraining's auc: 0.994739\tvalid_1's auc: 0.947961\n",
      "[410]\ttraining's auc: 0.994905\tvalid_1's auc: 0.948151\n",
      "[420]\ttraining's auc: 0.995317\tvalid_1's auc: 0.948669\n",
      "[430]\ttraining's auc: 0.995822\tvalid_1's auc: 0.948749\n",
      "[440]\ttraining's auc: 0.996026\tvalid_1's auc: 0.949015\n",
      "[450]\ttraining's auc: 0.996204\tvalid_1's auc: 0.949002\n",
      "[460]\ttraining's auc: 0.996374\tvalid_1's auc: 0.949337\n",
      "[470]\ttraining's auc: 0.99663\tvalid_1's auc: 0.949684\n",
      "[480]\ttraining's auc: 0.996756\tvalid_1's auc: 0.949789\n",
      "[490]\ttraining's auc: 0.996966\tvalid_1's auc: 0.949768\n",
      "[500]\ttraining's auc: 0.99716\tvalid_1's auc: 0.949805\n",
      "[510]\ttraining's auc: 0.997316\tvalid_1's auc: 0.950068\n",
      "[520]\ttraining's auc: 0.997423\tvalid_1's auc: 0.950106\n",
      "[530]\ttraining's auc: 0.99758\tvalid_1's auc: 0.950214\n",
      "[540]\ttraining's auc: 0.997757\tvalid_1's auc: 0.950146\n",
      "[550]\ttraining's auc: 0.997847\tvalid_1's auc: 0.950242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(max_depth=30, metric='auc', n_estimators=3000, n_jobs=10,\n",
       "               objective='binary', seed=29)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_model_without_cat = lgbm.LGBMClassifier(**params_lgbm)\n",
    "lgbm_model_without_cat.fit(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    early_stopping_rounds=25,\n",
    "    eval_metric=\"auc\",\n",
    "    verbose=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение на всех признаках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция обработки пропускув в категориальных фичах\n",
    "def missing_cat_features(X):\n",
    "    for feature in cat_features:\n",
    "        X.loc[X[feature].isna(), feature] = X[feature].mode()[0]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = missing_cat_features(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card5</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>...</th>\n",
       "      <th>M1_T</th>\n",
       "      <th>M2_T</th>\n",
       "      <th>M3_T</th>\n",
       "      <th>M4_M1</th>\n",
       "      <th>M4_M2</th>\n",
       "      <th>M5_T</th>\n",
       "      <th>M6_T</th>\n",
       "      <th>M7_T</th>\n",
       "      <th>M8_T</th>\n",
       "      <th>M9_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3076999.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1884075</td>\n",
       "      <td>68.5</td>\n",
       "      <td>13926</td>\n",
       "      <td>375.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3076999.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1884075</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3076999.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1884075</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3076999.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1884075</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9633</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3076999.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1884075</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 517 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt  card1  card2  card3  \\\n",
       "0      3076999.5        0        1884075            68.5  13926  375.0  150.0   \n",
       "1      3076999.5        0        1884075            29.0   2755  404.0  150.0   \n",
       "2      3076999.5        0        1884075            59.0   4663  490.0  150.0   \n",
       "3      3076999.5        0        1884075            50.0   9633  567.0  150.0   \n",
       "4      3076999.5        0        1884075            50.0   4497  514.0  150.0   \n",
       "\n",
       "   card5  addr1  addr2  ...  M1_T  M2_T  M3_T  M4_M1  M4_M2  M5_T  M6_T  M7_T  \\\n",
       "0  142.0  315.0   87.0  ...     1     1     1      0      1     0     1     0   \n",
       "1  102.0  325.0   87.0  ...     1     1     1      0      0     1     1     0   \n",
       "2  166.0  330.0   87.0  ...     1     1     1      0      0     0     0     0   \n",
       "3  117.0  476.0   87.0  ...     1     1     1      0      0     1     0     0   \n",
       "4  102.0  420.0   87.0  ...     1     1     1      0      0     0     0     0   \n",
       "\n",
       "   M8_T  M9_T  \n",
       "0     0     1  \n",
       "1     0     1  \n",
       "2     0     0  \n",
       "3     0     1  \n",
       "4     0     1  \n",
       "\n",
       "[5 rows x 517 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#кодируем все категориальные признаки с помощью get_dummies\n",
    "train_data = pd.get_dummies(train_data, columns = cat_features, prefix_sep = \"_\", drop_first = True) \n",
    "test_data = pd.get_dummies(test_data, columns = cat_features, prefix_sep = \"_\", drop_first = True) \n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180000, 517)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "516"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_feature_after_preproc = train_data.columns.drop([target]).tolist()\n",
    "len(num_feature_after_preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data[num_feature_after_preproc]\n",
    "y = train_data[target]\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 3000,\n",
    "    \"reg_lambda\": 50,\n",
    "    \"max_depth\": 20,\n",
    "    \"gamma\": 5,\n",
    "    \"nthread\": 4,\n",
    "    \"seed\": 29\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kosfo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.68706\tvalidation_1-auc:0.68248\n",
      "[10]\tvalidation_0-auc:0.82957\tvalidation_1-auc:0.82026\n",
      "[20]\tvalidation_0-auc:0.86766\tvalidation_1-auc:0.85698\n",
      "[30]\tvalidation_0-auc:0.89096\tvalidation_1-auc:0.88062\n",
      "[40]\tvalidation_0-auc:0.90583\tvalidation_1-auc:0.89489\n",
      "[50]\tvalidation_0-auc:0.91738\tvalidation_1-auc:0.90213\n",
      "[60]\tvalidation_0-auc:0.92669\tvalidation_1-auc:0.90915\n",
      "[70]\tvalidation_0-auc:0.93244\tvalidation_1-auc:0.91325\n",
      "[80]\tvalidation_0-auc:0.93728\tvalidation_1-auc:0.91639\n",
      "[90]\tvalidation_0-auc:0.94020\tvalidation_1-auc:0.91913\n",
      "[100]\tvalidation_0-auc:0.94298\tvalidation_1-auc:0.92166\n",
      "[110]\tvalidation_0-auc:0.94561\tvalidation_1-auc:0.92375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-208-00333a8bad0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mxgb_model_with_cat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams_xgb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m xgb_model_with_cat.fit(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1174\u001b[0m         )\n\u001b[0;32m   1175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m         self._Booster = train(\n\u001b[0m\u001b[0;32m   1177\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \"\"\"\n\u001b[1;32m--> 189\u001b[1;33m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    190\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1499\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1500\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1501\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb_model_with_cat = xgb.XGBClassifier(**params_xgb)\n",
    "xgb_model_with_cat.fit(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    early_stopping_rounds=20,\n",
    "    eval_metric=\"auc\",\n",
    "    verbose=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgbm = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 3000,\n",
    "    \"n_jobs\": 10,\n",
    "    \"max_depth\": 30,\n",
    "    \"seed\": 29\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model_with_cat = lgbm.LGBMClassifier(**params_lgbm)\n",
    "lgbm_model_with_cat.fit(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    early_stopping_rounds=25,\n",
    "    eval_metric=\"auc\",\n",
    "    verbose=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_catb = {\n",
    "    \"n_estimators\": 3000,\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"eval_metric\": \"AUC\",\n",
    "    \"task_type\": \"CPU\",\n",
    "    \"max_bin\": 20,\n",
    "    \"verbose\": 10,\n",
    "    \"max_depth\": 6,\n",
    "    \"l2_leaf_reg\": 0.1,\n",
    "    \"early_stopping_rounds\": 50,\n",
    "    \"thread_count\": 6,\n",
    "    \"random_seed\": 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d60ff60f034400b19c3964ee79c4c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6078127\ttest1: 0.6017316\tbest: 0.6017316 (0)\ttotal: 103ms\tremaining: 5m 8s\n",
      "10:\ttest: 0.7999502\ttest1: 0.7894058\tbest: 0.7894058 (10)\ttotal: 1.21s\tremaining: 5m 27s\n",
      "20:\ttest: 0.8053692\ttest1: 0.7967832\tbest: 0.7967832 (20)\ttotal: 2.35s\tremaining: 5m 33s\n",
      "30:\ttest: 0.8282990\ttest1: 0.8249925\tbest: 0.8253179 (28)\ttotal: 3.59s\tremaining: 5m 43s\n",
      "40:\ttest: 0.8317307\ttest1: 0.8276816\tbest: 0.8281166 (35)\ttotal: 4.77s\tremaining: 5m 44s\n",
      "50:\ttest: 0.8399939\ttest1: 0.8362429\tbest: 0.8362429 (50)\ttotal: 6.06s\tremaining: 5m 50s\n",
      "60:\ttest: 0.8484316\ttest1: 0.8446597\tbest: 0.8446597 (60)\ttotal: 7.3s\tremaining: 5m 51s\n",
      "70:\ttest: 0.8523578\ttest1: 0.8484551\tbest: 0.8484551 (70)\ttotal: 8.6s\tremaining: 5m 54s\n",
      "80:\ttest: 0.8551114\ttest1: 0.8511726\tbest: 0.8511726 (80)\ttotal: 9.86s\tremaining: 5m 55s\n",
      "90:\ttest: 0.8591286\ttest1: 0.8556459\tbest: 0.8556459 (90)\ttotal: 11.2s\tremaining: 5m 56s\n",
      "100:\ttest: 0.8613628\ttest1: 0.8572508\tbest: 0.8572508 (100)\ttotal: 12.4s\tremaining: 5m 57s\n",
      "110:\ttest: 0.8650531\ttest1: 0.8612226\tbest: 0.8612226 (110)\ttotal: 13.7s\tremaining: 5m 57s\n",
      "120:\ttest: 0.8675503\ttest1: 0.8638438\tbest: 0.8638438 (120)\ttotal: 15s\tremaining: 5m 57s\n",
      "130:\ttest: 0.8696659\ttest1: 0.8662654\tbest: 0.8662654 (130)\ttotal: 16.2s\tremaining: 5m 55s\n",
      "140:\ttest: 0.8717748\ttest1: 0.8683713\tbest: 0.8683713 (140)\ttotal: 17.5s\tremaining: 5m 55s\n",
      "150:\ttest: 0.8732042\ttest1: 0.8697894\tbest: 0.8697894 (150)\ttotal: 18.8s\tremaining: 5m 53s\n",
      "160:\ttest: 0.8751097\ttest1: 0.8716329\tbest: 0.8716329 (160)\ttotal: 20.1s\tremaining: 5m 54s\n",
      "170:\ttest: 0.8767788\ttest1: 0.8731350\tbest: 0.8731350 (170)\ttotal: 21.4s\tremaining: 5m 53s\n",
      "180:\ttest: 0.8781383\ttest1: 0.8744331\tbest: 0.8744331 (180)\ttotal: 22.7s\tremaining: 5m 53s\n",
      "190:\ttest: 0.8792683\ttest1: 0.8754024\tbest: 0.8754024 (190)\ttotal: 24s\tremaining: 5m 52s\n",
      "200:\ttest: 0.8802458\ttest1: 0.8764335\tbest: 0.8764335 (200)\ttotal: 25.3s\tremaining: 5m 51s\n",
      "210:\ttest: 0.8811184\ttest1: 0.8771335\tbest: 0.8771359 (209)\ttotal: 26.5s\tremaining: 5m 50s\n",
      "220:\ttest: 0.8821108\ttest1: 0.8783574\tbest: 0.8783574 (220)\ttotal: 27.8s\tremaining: 5m 49s\n",
      "230:\ttest: 0.8830572\ttest1: 0.8791720\tbest: 0.8791720 (230)\ttotal: 29.1s\tremaining: 5m 48s\n",
      "240:\ttest: 0.8841565\ttest1: 0.8803095\tbest: 0.8803095 (240)\ttotal: 30.3s\tremaining: 5m 46s\n",
      "250:\ttest: 0.8848021\ttest1: 0.8811291\tbest: 0.8811291 (250)\ttotal: 31.6s\tremaining: 5m 45s\n",
      "260:\ttest: 0.8853743\ttest1: 0.8817646\tbest: 0.8817646 (260)\ttotal: 32.9s\tremaining: 5m 44s\n",
      "270:\ttest: 0.8858851\ttest1: 0.8823184\tbest: 0.8823184 (270)\ttotal: 34.1s\tremaining: 5m 42s\n",
      "280:\ttest: 0.8866856\ttest1: 0.8830838\tbest: 0.8830838 (280)\ttotal: 35.3s\tremaining: 5m 41s\n",
      "290:\ttest: 0.8875802\ttest1: 0.8837976\tbest: 0.8837976 (290)\ttotal: 36.6s\tremaining: 5m 40s\n",
      "300:\ttest: 0.8884490\ttest1: 0.8844051\tbest: 0.8844051 (300)\ttotal: 37.9s\tremaining: 5m 39s\n",
      "310:\ttest: 0.8889195\ttest1: 0.8847243\tbest: 0.8847243 (310)\ttotal: 39s\tremaining: 5m 37s\n",
      "320:\ttest: 0.8894659\ttest1: 0.8851728\tbest: 0.8851728 (320)\ttotal: 40.3s\tremaining: 5m 36s\n",
      "330:\ttest: 0.8899868\ttest1: 0.8855782\tbest: 0.8855782 (330)\ttotal: 41.5s\tremaining: 5m 34s\n",
      "340:\ttest: 0.8906627\ttest1: 0.8861294\tbest: 0.8861294 (340)\ttotal: 42.8s\tremaining: 5m 33s\n",
      "350:\ttest: 0.8912177\ttest1: 0.8864711\tbest: 0.8864711 (350)\ttotal: 44s\tremaining: 5m 31s\n",
      "360:\ttest: 0.8919121\ttest1: 0.8868598\tbest: 0.8868598 (360)\ttotal: 45.4s\tremaining: 5m 32s\n",
      "370:\ttest: 0.8923549\ttest1: 0.8872355\tbest: 0.8872355 (370)\ttotal: 46.7s\tremaining: 5m 30s\n",
      "380:\ttest: 0.8928150\ttest1: 0.8875901\tbest: 0.8875943 (379)\ttotal: 48s\tremaining: 5m 29s\n",
      "390:\ttest: 0.8932302\ttest1: 0.8879289\tbest: 0.8879289 (390)\ttotal: 49.2s\tremaining: 5m 28s\n",
      "400:\ttest: 0.8935893\ttest1: 0.8882230\tbest: 0.8882230 (400)\ttotal: 50.5s\tremaining: 5m 27s\n",
      "410:\ttest: 0.8939868\ttest1: 0.8885788\tbest: 0.8885788 (410)\ttotal: 51.7s\tremaining: 5m 25s\n",
      "420:\ttest: 0.8943631\ttest1: 0.8888786\tbest: 0.8888786 (420)\ttotal: 53.1s\tremaining: 5m 25s\n",
      "430:\ttest: 0.8947595\ttest1: 0.8892404\tbest: 0.8892404 (430)\ttotal: 54.3s\tremaining: 5m 23s\n",
      "440:\ttest: 0.8949408\ttest1: 0.8893720\tbest: 0.8893720 (440)\ttotal: 55.5s\tremaining: 5m 22s\n",
      "450:\ttest: 0.8952672\ttest1: 0.8896575\tbest: 0.8896599 (448)\ttotal: 56.8s\tremaining: 5m 20s\n",
      "460:\ttest: 0.8956299\ttest1: 0.8899712\tbest: 0.8899712 (460)\ttotal: 58.1s\tremaining: 5m 19s\n",
      "470:\ttest: 0.8959158\ttest1: 0.8902010\tbest: 0.8902010 (470)\ttotal: 59.4s\tremaining: 5m 18s\n",
      "480:\ttest: 0.8962246\ttest1: 0.8904335\tbest: 0.8904335 (480)\ttotal: 1m\tremaining: 5m 17s\n",
      "490:\ttest: 0.8964162\ttest1: 0.8905834\tbest: 0.8905834 (490)\ttotal: 1m 1s\tremaining: 5m 16s\n",
      "500:\ttest: 0.8966681\ttest1: 0.8908898\tbest: 0.8908898 (500)\ttotal: 1m 3s\tremaining: 5m 14s\n",
      "510:\ttest: 0.8971007\ttest1: 0.8911914\tbest: 0.8911914 (510)\ttotal: 1m 4s\tremaining: 5m 13s\n",
      "520:\ttest: 0.8973405\ttest1: 0.8914112\tbest: 0.8914112 (520)\ttotal: 1m 5s\tremaining: 5m 12s\n",
      "530:\ttest: 0.8976467\ttest1: 0.8917303\tbest: 0.8917303 (530)\ttotal: 1m 6s\tremaining: 5m 11s\n",
      "540:\ttest: 0.8979265\ttest1: 0.8919546\tbest: 0.8919546 (540)\ttotal: 1m 8s\tremaining: 5m 9s\n",
      "550:\ttest: 0.8982196\ttest1: 0.8922612\tbest: 0.8922612 (550)\ttotal: 1m 9s\tremaining: 5m 8s\n",
      "560:\ttest: 0.8984580\ttest1: 0.8924043\tbest: 0.8924043 (560)\ttotal: 1m 10s\tremaining: 5m 6s\n",
      "570:\ttest: 0.8987306\ttest1: 0.8926648\tbest: 0.8926648 (570)\ttotal: 1m 11s\tremaining: 5m 5s\n",
      "580:\ttest: 0.8990130\ttest1: 0.8928935\tbest: 0.8929211 (578)\ttotal: 1m 13s\tremaining: 5m 4s\n",
      "590:\ttest: 0.8993009\ttest1: 0.8931875\tbest: 0.8931888 (589)\ttotal: 1m 14s\tremaining: 5m 2s\n",
      "600:\ttest: 0.8995006\ttest1: 0.8933787\tbest: 0.8933787 (600)\ttotal: 1m 15s\tremaining: 5m 1s\n",
      "610:\ttest: 0.8996850\ttest1: 0.8934508\tbest: 0.8934581 (608)\ttotal: 1m 16s\tremaining: 4m 59s\n",
      "620:\ttest: 0.9000282\ttest1: 0.8937610\tbest: 0.8937705 (619)\ttotal: 1m 17s\tremaining: 4m 58s\n",
      "630:\ttest: 0.9002883\ttest1: 0.8939212\tbest: 0.8939212 (630)\ttotal: 1m 19s\tremaining: 4m 57s\n",
      "640:\ttest: 0.9004477\ttest1: 0.8940805\tbest: 0.8940805 (640)\ttotal: 1m 20s\tremaining: 4m 55s\n",
      "650:\ttest: 0.9007614\ttest1: 0.8942600\tbest: 0.8942727 (648)\ttotal: 1m 21s\tremaining: 4m 54s\n",
      "660:\ttest: 0.9012389\ttest1: 0.8946336\tbest: 0.8946336 (660)\ttotal: 1m 23s\tremaining: 4m 53s\n",
      "670:\ttest: 0.9015288\ttest1: 0.8949233\tbest: 0.8949233 (670)\ttotal: 1m 24s\tremaining: 4m 52s\n",
      "680:\ttest: 0.9017709\ttest1: 0.8951552\tbest: 0.8951552 (680)\ttotal: 1m 25s\tremaining: 4m 51s\n",
      "690:\ttest: 0.9020044\ttest1: 0.8952804\tbest: 0.8952804 (690)\ttotal: 1m 26s\tremaining: 4m 50s\n",
      "700:\ttest: 0.9023498\ttest1: 0.8955301\tbest: 0.8955330 (699)\ttotal: 1m 28s\tremaining: 4m 48s\n",
      "710:\ttest: 0.9026893\ttest1: 0.8958086\tbest: 0.8958104 (709)\ttotal: 1m 29s\tremaining: 4m 47s\n",
      "720:\ttest: 0.9030299\ttest1: 0.8960021\tbest: 0.8960021 (720)\ttotal: 1m 30s\tremaining: 4m 46s\n",
      "730:\ttest: 0.9032483\ttest1: 0.8961744\tbest: 0.8961744 (730)\ttotal: 1m 31s\tremaining: 4m 44s\n",
      "740:\ttest: 0.9035711\ttest1: 0.8962806\tbest: 0.8963224 (738)\ttotal: 1m 33s\tremaining: 4m 44s\n",
      "750:\ttest: 0.9038325\ttest1: 0.8964352\tbest: 0.8964352 (750)\ttotal: 1m 34s\tremaining: 4m 42s\n",
      "760:\ttest: 0.9040514\ttest1: 0.8966058\tbest: 0.8966071 (759)\ttotal: 1m 35s\tremaining: 4m 41s\n",
      "770:\ttest: 0.9043296\ttest1: 0.8967158\tbest: 0.8967158 (770)\ttotal: 1m 36s\tremaining: 4m 40s\n",
      "780:\ttest: 0.9045932\ttest1: 0.8968168\tbest: 0.8968217 (776)\ttotal: 1m 38s\tremaining: 4m 39s\n",
      "790:\ttest: 0.9047906\ttest1: 0.8969658\tbest: 0.8969658 (790)\ttotal: 1m 39s\tremaining: 4m 37s\n",
      "800:\ttest: 0.9050207\ttest1: 0.8971344\tbest: 0.8971344 (800)\ttotal: 1m 40s\tremaining: 4m 36s\n",
      "810:\ttest: 0.9052059\ttest1: 0.8973098\tbest: 0.8973098 (810)\ttotal: 1m 42s\tremaining: 4m 35s\n",
      "820:\ttest: 0.9053870\ttest1: 0.8973441\tbest: 0.8973441 (820)\ttotal: 1m 43s\tremaining: 4m 34s\n",
      "830:\ttest: 0.9055991\ttest1: 0.8975568\tbest: 0.8975568 (830)\ttotal: 1m 44s\tremaining: 4m 32s\n",
      "840:\ttest: 0.9058194\ttest1: 0.8977645\tbest: 0.8977645 (840)\ttotal: 1m 45s\tremaining: 4m 31s\n",
      "850:\ttest: 0.9061018\ttest1: 0.8979629\tbest: 0.8979629 (850)\ttotal: 1m 47s\tremaining: 4m 30s\n",
      "860:\ttest: 0.9063940\ttest1: 0.8981376\tbest: 0.8981376 (860)\ttotal: 1m 48s\tremaining: 4m 29s\n",
      "870:\ttest: 0.9067174\ttest1: 0.8983871\tbest: 0.8983871 (870)\ttotal: 1m 49s\tremaining: 4m 28s\n",
      "880:\ttest: 0.9069086\ttest1: 0.8985253\tbest: 0.8985340 (878)\ttotal: 1m 51s\tremaining: 4m 27s\n",
      "890:\ttest: 0.9071342\ttest1: 0.8986846\tbest: 0.8987065 (889)\ttotal: 1m 52s\tremaining: 4m 25s\n",
      "900:\ttest: 0.9074463\ttest1: 0.8989191\tbest: 0.8989191 (900)\ttotal: 1m 53s\tremaining: 4m 24s\n",
      "910:\ttest: 0.9075500\ttest1: 0.8989937\tbest: 0.8989945 (909)\ttotal: 1m 54s\tremaining: 4m 23s\n",
      "920:\ttest: 0.9078457\ttest1: 0.8992460\tbest: 0.8992460 (920)\ttotal: 1m 56s\tremaining: 4m 22s\n",
      "930:\ttest: 0.9080875\ttest1: 0.8994522\tbest: 0.8994522 (930)\ttotal: 1m 57s\tremaining: 4m 20s\n",
      "940:\ttest: 0.9083762\ttest1: 0.8997114\tbest: 0.8997142 (938)\ttotal: 1m 58s\tremaining: 4m 19s\n",
      "950:\ttest: 0.9085290\ttest1: 0.8998434\tbest: 0.8998507 (948)\ttotal: 1m 59s\tremaining: 4m 18s\n",
      "960:\ttest: 0.9088280\ttest1: 0.9000446\tbest: 0.9000446 (960)\ttotal: 2m 1s\tremaining: 4m 17s\n",
      "970:\ttest: 0.9089739\ttest1: 0.9001931\tbest: 0.9001931 (970)\ttotal: 2m 2s\tremaining: 4m 15s\n",
      "980:\ttest: 0.9093198\ttest1: 0.9004360\tbest: 0.9004360 (980)\ttotal: 2m 3s\tremaining: 4m 14s\n",
      "990:\ttest: 0.9095697\ttest1: 0.9006090\tbest: 0.9006090 (990)\ttotal: 2m 5s\tremaining: 4m 13s\n",
      "1000:\ttest: 0.9097114\ttest1: 0.9007555\tbest: 0.9007555 (1000)\ttotal: 2m 6s\tremaining: 4m 12s\n",
      "1010:\ttest: 0.9098140\ttest1: 0.9008732\tbest: 0.9008732 (1010)\ttotal: 2m 7s\tremaining: 4m 10s\n",
      "1020:\ttest: 0.9101290\ttest1: 0.9010447\tbest: 0.9010501 (1019)\ttotal: 2m 8s\tremaining: 4m 9s\n",
      "1030:\ttest: 0.9103433\ttest1: 0.9012194\tbest: 0.9012194 (1030)\ttotal: 2m 10s\tremaining: 4m 8s\n",
      "1040:\ttest: 0.9104930\ttest1: 0.9013656\tbest: 0.9013656 (1040)\ttotal: 2m 11s\tremaining: 4m 7s\n",
      "1050:\ttest: 0.9106619\ttest1: 0.9015398\tbest: 0.9015398 (1050)\ttotal: 2m 12s\tremaining: 4m 6s\n",
      "1060:\ttest: 0.9108543\ttest1: 0.9017061\tbest: 0.9017061 (1060)\ttotal: 2m 14s\tremaining: 4m 5s\n",
      "1070:\ttest: 0.9109536\ttest1: 0.9017668\tbest: 0.9017668 (1070)\ttotal: 2m 15s\tremaining: 4m 3s\n",
      "1080:\ttest: 0.9110886\ttest1: 0.9018233\tbest: 0.9018233 (1080)\ttotal: 2m 16s\tremaining: 4m 2s\n",
      "1090:\ttest: 0.9112844\ttest1: 0.9019405\tbest: 0.9019405 (1090)\ttotal: 2m 17s\tremaining: 4m 1s\n",
      "1100:\ttest: 0.9115459\ttest1: 0.9021494\tbest: 0.9021494 (1100)\ttotal: 2m 19s\tremaining: 4m\n",
      "1110:\ttest: 0.9117815\ttest1: 0.9023263\tbest: 0.9023263 (1110)\ttotal: 2m 20s\tremaining: 3m 58s\n",
      "1120:\ttest: 0.9120081\ttest1: 0.9025298\tbest: 0.9025343 (1116)\ttotal: 2m 21s\tremaining: 3m 57s\n",
      "1130:\ttest: 0.9122191\ttest1: 0.9026785\tbest: 0.9026827 (1128)\ttotal: 2m 23s\tremaining: 3m 56s\n",
      "1140:\ttest: 0.9124965\ttest1: 0.9028116\tbest: 0.9028116 (1140)\ttotal: 2m 24s\tremaining: 3m 55s\n",
      "1150:\ttest: 0.9127035\ttest1: 0.9028976\tbest: 0.9029158 (1149)\ttotal: 2m 25s\tremaining: 3m 54s\n",
      "1160:\ttest: 0.9128839\ttest1: 0.9030958\tbest: 0.9030958 (1160)\ttotal: 2m 27s\tremaining: 3m 53s\n",
      "1170:\ttest: 0.9130466\ttest1: 0.9031975\tbest: 0.9031975 (1170)\ttotal: 2m 28s\tremaining: 3m 51s\n",
      "1180:\ttest: 0.9131566\ttest1: 0.9033342\tbest: 0.9033342 (1180)\ttotal: 2m 29s\tremaining: 3m 50s\n",
      "1190:\ttest: 0.9134134\ttest1: 0.9035790\tbest: 0.9035790 (1190)\ttotal: 2m 30s\tremaining: 3m 49s\n",
      "1200:\ttest: 0.9136123\ttest1: 0.9037952\tbest: 0.9037952 (1200)\ttotal: 2m 32s\tremaining: 3m 47s\n",
      "1210:\ttest: 0.9138784\ttest1: 0.9039464\tbest: 0.9039464 (1210)\ttotal: 2m 33s\tremaining: 3m 47s\n",
      "1220:\ttest: 0.9141138\ttest1: 0.9042265\tbest: 0.9042265 (1220)\ttotal: 2m 35s\tremaining: 3m 45s\n",
      "1230:\ttest: 0.9142763\ttest1: 0.9043160\tbest: 0.9043160 (1230)\ttotal: 2m 36s\tremaining: 3m 44s\n",
      "1240:\ttest: 0.9145014\ttest1: 0.9044104\tbest: 0.9044104 (1240)\ttotal: 2m 37s\tremaining: 3m 43s\n",
      "1250:\ttest: 0.9146781\ttest1: 0.9045442\tbest: 0.9045442 (1250)\ttotal: 2m 38s\tremaining: 3m 42s\n",
      "1260:\ttest: 0.9148586\ttest1: 0.9046367\tbest: 0.9046475 (1257)\ttotal: 2m 40s\tremaining: 3m 40s\n",
      "1270:\ttest: 0.9150483\ttest1: 0.9047638\tbest: 0.9047638 (1270)\ttotal: 2m 41s\tremaining: 3m 39s\n",
      "1280:\ttest: 0.9152835\ttest1: 0.9049374\tbest: 0.9049374 (1280)\ttotal: 2m 42s\tremaining: 3m 38s\n",
      "1290:\ttest: 0.9154830\ttest1: 0.9050905\tbest: 0.9050905 (1290)\ttotal: 2m 44s\tremaining: 3m 37s\n",
      "1300:\ttest: 0.9156919\ttest1: 0.9052648\tbest: 0.9052648 (1300)\ttotal: 2m 45s\tremaining: 3m 36s\n",
      "1310:\ttest: 0.9158603\ttest1: 0.9054132\tbest: 0.9054132 (1310)\ttotal: 2m 46s\tremaining: 3m 35s\n",
      "1320:\ttest: 0.9159907\ttest1: 0.9055414\tbest: 0.9055414 (1320)\ttotal: 2m 48s\tremaining: 3m 33s\n",
      "1330:\ttest: 0.9161624\ttest1: 0.9056838\tbest: 0.9056838 (1330)\ttotal: 2m 49s\tremaining: 3m 32s\n",
      "1340:\ttest: 0.9163254\ttest1: 0.9057818\tbest: 0.9057818 (1340)\ttotal: 2m 50s\tremaining: 3m 31s\n",
      "1350:\ttest: 0.9165035\ttest1: 0.9059098\tbest: 0.9059098 (1350)\ttotal: 2m 52s\tremaining: 3m 30s\n",
      "1360:\ttest: 0.9166882\ttest1: 0.9060375\tbest: 0.9060375 (1360)\ttotal: 2m 53s\tremaining: 3m 28s\n",
      "1370:\ttest: 0.9167745\ttest1: 0.9060999\tbest: 0.9060999 (1370)\ttotal: 2m 54s\tremaining: 3m 27s\n",
      "1380:\ttest: 0.9169587\ttest1: 0.9063300\tbest: 0.9063300 (1380)\ttotal: 2m 56s\tremaining: 3m 26s\n",
      "1390:\ttest: 0.9170633\ttest1: 0.9063815\tbest: 0.9063815 (1390)\ttotal: 2m 57s\tremaining: 3m 25s\n",
      "1400:\ttest: 0.9172511\ttest1: 0.9064933\tbest: 0.9064933 (1400)\ttotal: 2m 58s\tremaining: 3m 23s\n",
      "1410:\ttest: 0.9174416\ttest1: 0.9066021\tbest: 0.9066021 (1410)\ttotal: 2m 59s\tremaining: 3m 22s\n",
      "1420:\ttest: 0.9176205\ttest1: 0.9067690\tbest: 0.9067690 (1420)\ttotal: 3m 1s\tremaining: 3m 21s\n",
      "1430:\ttest: 0.9177493\ttest1: 0.9069067\tbest: 0.9069067 (1430)\ttotal: 3m 2s\tremaining: 3m 20s\n",
      "1440:\ttest: 0.9178930\ttest1: 0.9069779\tbest: 0.9069779 (1440)\ttotal: 3m 3s\tremaining: 3m 18s\n",
      "1450:\ttest: 0.9179739\ttest1: 0.9069918\tbest: 0.9069938 (1445)\ttotal: 3m 4s\tremaining: 3m 17s\n",
      "1460:\ttest: 0.9181655\ttest1: 0.9070857\tbest: 0.9070857 (1460)\ttotal: 3m 6s\tremaining: 3m 16s\n",
      "1470:\ttest: 0.9182791\ttest1: 0.9071965\tbest: 0.9071965 (1470)\ttotal: 3m 7s\tremaining: 3m 15s\n",
      "1480:\ttest: 0.9183622\ttest1: 0.9072372\tbest: 0.9072397 (1477)\ttotal: 3m 9s\tremaining: 3m 13s\n",
      "1490:\ttest: 0.9184988\ttest1: 0.9073054\tbest: 0.9073062 (1489)\ttotal: 3m 10s\tremaining: 3m 12s\n",
      "1500:\ttest: 0.9186196\ttest1: 0.9074317\tbest: 0.9074317 (1500)\ttotal: 3m 11s\tremaining: 3m 11s\n",
      "1510:\ttest: 0.9187245\ttest1: 0.9075308\tbest: 0.9075308 (1510)\ttotal: 3m 12s\tremaining: 3m 10s\n",
      "1520:\ttest: 0.9188380\ttest1: 0.9076897\tbest: 0.9076897 (1520)\ttotal: 3m 14s\tremaining: 3m 8s\n",
      "1530:\ttest: 0.9190498\ttest1: 0.9077845\tbest: 0.9077845 (1530)\ttotal: 3m 15s\tremaining: 3m 7s\n",
      "1540:\ttest: 0.9191719\ttest1: 0.9079036\tbest: 0.9079038 (1539)\ttotal: 3m 16s\tremaining: 3m 6s\n",
      "1550:\ttest: 0.9192648\ttest1: 0.9079757\tbest: 0.9079757 (1550)\ttotal: 3m 18s\tremaining: 3m 5s\n",
      "1560:\ttest: 0.9193220\ttest1: 0.9079977\tbest: 0.9080007 (1553)\ttotal: 3m 19s\tremaining: 3m 3s\n",
      "1570:\ttest: 0.9194457\ttest1: 0.9080925\tbest: 0.9080925 (1570)\ttotal: 3m 20s\tremaining: 3m 2s\n",
      "1580:\ttest: 0.9195923\ttest1: 0.9082108\tbest: 0.9082108 (1580)\ttotal: 3m 21s\tremaining: 3m 1s\n",
      "1590:\ttest: 0.9196972\ttest1: 0.9082444\tbest: 0.9082444 (1590)\ttotal: 3m 23s\tremaining: 3m\n",
      "1600:\ttest: 0.9197984\ttest1: 0.9082914\tbest: 0.9082966 (1599)\ttotal: 3m 24s\tremaining: 2m 58s\n",
      "1610:\ttest: 0.9199313\ttest1: 0.9083773\tbest: 0.9083773 (1610)\ttotal: 3m 26s\tremaining: 2m 58s\n",
      "1620:\ttest: 0.9200594\ttest1: 0.9085288\tbest: 0.9085288 (1620)\ttotal: 3m 27s\tremaining: 2m 56s\n",
      "1630:\ttest: 0.9201824\ttest1: 0.9086343\tbest: 0.9086343 (1630)\ttotal: 3m 29s\tremaining: 2m 55s\n",
      "1640:\ttest: 0.9202612\ttest1: 0.9086925\tbest: 0.9086947 (1639)\ttotal: 3m 30s\tremaining: 2m 54s\n",
      "1650:\ttest: 0.9203582\ttest1: 0.9087565\tbest: 0.9087565 (1650)\ttotal: 3m 31s\tremaining: 2m 53s\n",
      "1660:\ttest: 0.9204288\ttest1: 0.9088123\tbest: 0.9088123 (1660)\ttotal: 3m 33s\tremaining: 2m 52s\n",
      "1670:\ttest: 0.9205771\ttest1: 0.9089580\tbest: 0.9089580 (1670)\ttotal: 3m 34s\tremaining: 2m 50s\n",
      "1680:\ttest: 0.9207127\ttest1: 0.9091299\tbest: 0.9091299 (1680)\ttotal: 3m 36s\tremaining: 2m 49s\n",
      "1690:\ttest: 0.9208658\ttest1: 0.9092422\tbest: 0.9092422 (1690)\ttotal: 3m 37s\tremaining: 2m 48s\n",
      "1700:\ttest: 0.9210250\ttest1: 0.9093462\tbest: 0.9093462 (1700)\ttotal: 3m 38s\tremaining: 2m 47s\n",
      "1710:\ttest: 0.9211701\ttest1: 0.9094548\tbest: 0.9094548 (1710)\ttotal: 3m 40s\tremaining: 2m 45s\n",
      "1720:\ttest: 0.9213059\ttest1: 0.9095261\tbest: 0.9095302 (1716)\ttotal: 3m 41s\tremaining: 2m 44s\n",
      "1730:\ttest: 0.9213844\ttest1: 0.9095570\tbest: 0.9095633 (1729)\ttotal: 3m 42s\tremaining: 2m 43s\n",
      "1740:\ttest: 0.9214598\ttest1: 0.9096224\tbest: 0.9096224 (1740)\ttotal: 3m 44s\tremaining: 2m 42s\n",
      "1750:\ttest: 0.9215900\ttest1: 0.9097602\tbest: 0.9097602 (1750)\ttotal: 3m 45s\tremaining: 2m 40s\n",
      "1760:\ttest: 0.9216591\ttest1: 0.9098062\tbest: 0.9098085 (1758)\ttotal: 3m 46s\tremaining: 2m 39s\n",
      "1770:\ttest: 0.9217205\ttest1: 0.9098412\tbest: 0.9098412 (1770)\ttotal: 3m 47s\tremaining: 2m 38s\n",
      "1780:\ttest: 0.9217890\ttest1: 0.9099175\tbest: 0.9099194 (1777)\ttotal: 3m 49s\tremaining: 2m 36s\n",
      "1790:\ttest: 0.9218762\ttest1: 0.9099825\tbest: 0.9099825 (1790)\ttotal: 3m 50s\tremaining: 2m 35s\n",
      "1800:\ttest: 0.9219199\ttest1: 0.9100194\tbest: 0.9100221 (1798)\ttotal: 3m 51s\tremaining: 2m 34s\n",
      "1810:\ttest: 0.9219377\ttest1: 0.9100281\tbest: 0.9100283 (1809)\ttotal: 3m 53s\tremaining: 2m 33s\n",
      "1820:\ttest: 0.9220351\ttest1: 0.9101293\tbest: 0.9101293 (1820)\ttotal: 3m 54s\tremaining: 2m 31s\n",
      "1830:\ttest: 0.9220855\ttest1: 0.9102046\tbest: 0.9102046 (1830)\ttotal: 3m 55s\tremaining: 2m 30s\n",
      "1840:\ttest: 0.9221757\ttest1: 0.9102839\tbest: 0.9102840 (1838)\ttotal: 3m 56s\tremaining: 2m 29s\n",
      "1850:\ttest: 0.9222981\ttest1: 0.9103301\tbest: 0.9103301 (1850)\ttotal: 3m 58s\tremaining: 2m 27s\n",
      "1860:\ttest: 0.9224064\ttest1: 0.9104122\tbest: 0.9104122 (1860)\ttotal: 3m 59s\tremaining: 2m 26s\n",
      "1870:\ttest: 0.9225329\ttest1: 0.9105461\tbest: 0.9105461 (1870)\ttotal: 4m 1s\tremaining: 2m 25s\n",
      "1880:\ttest: 0.9226555\ttest1: 0.9106045\tbest: 0.9106046 (1879)\ttotal: 4m 2s\tremaining: 2m 24s\n",
      "1890:\ttest: 0.9228340\ttest1: 0.9107418\tbest: 0.9107418 (1890)\ttotal: 4m 3s\tremaining: 2m 22s\n",
      "1900:\ttest: 0.9229276\ttest1: 0.9107679\tbest: 0.9107679 (1900)\ttotal: 4m 5s\tremaining: 2m 21s\n",
      "1910:\ttest: 0.9230269\ttest1: 0.9108742\tbest: 0.9108742 (1910)\ttotal: 4m 6s\tremaining: 2m 20s\n",
      "1920:\ttest: 0.9231688\ttest1: 0.9109796\tbest: 0.9109796 (1920)\ttotal: 4m 8s\tremaining: 2m 19s\n",
      "1930:\ttest: 0.9233386\ttest1: 0.9110672\tbest: 0.9110672 (1930)\ttotal: 4m 9s\tremaining: 2m 18s\n",
      "1940:\ttest: 0.9234570\ttest1: 0.9111542\tbest: 0.9111542 (1940)\ttotal: 4m 10s\tremaining: 2m 16s\n",
      "1950:\ttest: 0.9235770\ttest1: 0.9112706\tbest: 0.9112706 (1950)\ttotal: 4m 11s\tremaining: 2m 15s\n",
      "1960:\ttest: 0.9236771\ttest1: 0.9113050\tbest: 0.9113051 (1959)\ttotal: 4m 13s\tremaining: 2m 14s\n",
      "1970:\ttest: 0.9237447\ttest1: 0.9113383\tbest: 0.9113395 (1969)\ttotal: 4m 14s\tremaining: 2m 13s\n",
      "1980:\ttest: 0.9238329\ttest1: 0.9114149\tbest: 0.9114155 (1979)\ttotal: 4m 16s\tremaining: 2m 11s\n",
      "1990:\ttest: 0.9239782\ttest1: 0.9115039\tbest: 0.9115112 (1986)\ttotal: 4m 17s\tremaining: 2m 10s\n",
      "2000:\ttest: 0.9241043\ttest1: 0.9115620\tbest: 0.9115620 (2000)\ttotal: 4m 18s\tremaining: 2m 9s\n",
      "2010:\ttest: 0.9241639\ttest1: 0.9115991\tbest: 0.9115991 (2010)\ttotal: 4m 19s\tremaining: 2m 7s\n",
      "2020:\ttest: 0.9243038\ttest1: 0.9116984\tbest: 0.9116984 (2020)\ttotal: 4m 21s\tremaining: 2m 6s\n",
      "2030:\ttest: 0.9244541\ttest1: 0.9118186\tbest: 0.9118186 (2030)\ttotal: 4m 22s\tremaining: 2m 5s\n",
      "2040:\ttest: 0.9245299\ttest1: 0.9118636\tbest: 0.9118755 (2039)\ttotal: 4m 24s\tremaining: 2m 4s\n",
      "2050:\ttest: 0.9246303\ttest1: 0.9118812\tbest: 0.9118878 (2042)\ttotal: 4m 25s\tremaining: 2m 2s\n",
      "2060:\ttest: 0.9247377\ttest1: 0.9119723\tbest: 0.9119723 (2060)\ttotal: 4m 26s\tremaining: 2m 1s\n",
      "2070:\ttest: 0.9248222\ttest1: 0.9120241\tbest: 0.9120241 (2070)\ttotal: 4m 28s\tremaining: 2m\n",
      "2080:\ttest: 0.9249126\ttest1: 0.9120568\tbest: 0.9120600 (2079)\ttotal: 4m 29s\tremaining: 1m 59s\n",
      "2090:\ttest: 0.9250642\ttest1: 0.9122064\tbest: 0.9122064 (2090)\ttotal: 4m 31s\tremaining: 1m 57s\n",
      "2100:\ttest: 0.9251891\ttest1: 0.9122866\tbest: 0.9122866 (2100)\ttotal: 4m 32s\tremaining: 1m 56s\n",
      "2110:\ttest: 0.9253662\ttest1: 0.9123277\tbest: 0.9123568 (2106)\ttotal: 4m 33s\tremaining: 1m 55s\n",
      "2120:\ttest: 0.9254607\ttest1: 0.9124251\tbest: 0.9124281 (2118)\ttotal: 4m 35s\tremaining: 1m 54s\n",
      "2130:\ttest: 0.9256307\ttest1: 0.9125679\tbest: 0.9125679 (2130)\ttotal: 4m 36s\tremaining: 1m 52s\n",
      "2140:\ttest: 0.9257154\ttest1: 0.9126048\tbest: 0.9126048 (2140)\ttotal: 4m 37s\tremaining: 1m 51s\n",
      "2150:\ttest: 0.9258123\ttest1: 0.9126506\tbest: 0.9126506 (2150)\ttotal: 4m 39s\tremaining: 1m 50s\n",
      "2160:\ttest: 0.9259226\ttest1: 0.9127069\tbest: 0.9127069 (2160)\ttotal: 4m 41s\tremaining: 1m 49s\n",
      "2170:\ttest: 0.9260319\ttest1: 0.9127448\tbest: 0.9127448 (2170)\ttotal: 4m 42s\tremaining: 1m 47s\n",
      "2180:\ttest: 0.9261881\ttest1: 0.9128243\tbest: 0.9128243 (2180)\ttotal: 4m 43s\tremaining: 1m 46s\n",
      "2190:\ttest: 0.9262846\ttest1: 0.9128498\tbest: 0.9128596 (2186)\ttotal: 4m 45s\tremaining: 1m 45s\n",
      "2200:\ttest: 0.9263318\ttest1: 0.9128723\tbest: 0.9128723 (2200)\ttotal: 4m 46s\tremaining: 1m 44s\n",
      "2210:\ttest: 0.9264571\ttest1: 0.9129554\tbest: 0.9129554 (2210)\ttotal: 4m 47s\tremaining: 1m 42s\n",
      "2220:\ttest: 0.9266297\ttest1: 0.9130347\tbest: 0.9130375 (2219)\ttotal: 4m 49s\tremaining: 1m 41s\n",
      "2230:\ttest: 0.9268029\ttest1: 0.9131376\tbest: 0.9131376 (2230)\ttotal: 4m 50s\tremaining: 1m 40s\n",
      "2240:\ttest: 0.9270049\ttest1: 0.9132649\tbest: 0.9132649 (2240)\ttotal: 4m 51s\tremaining: 1m 38s\n",
      "2250:\ttest: 0.9270439\ttest1: 0.9133266\tbest: 0.9133266 (2250)\ttotal: 4m 53s\tremaining: 1m 37s\n",
      "2260:\ttest: 0.9271306\ttest1: 0.9133988\tbest: 0.9133988 (2260)\ttotal: 4m 54s\tremaining: 1m 36s\n",
      "2270:\ttest: 0.9272561\ttest1: 0.9134493\tbest: 0.9134528 (2267)\ttotal: 4m 56s\tremaining: 1m 35s\n",
      "2280:\ttest: 0.9273429\ttest1: 0.9135191\tbest: 0.9135191 (2280)\ttotal: 4m 57s\tremaining: 1m 33s\n",
      "2290:\ttest: 0.9274252\ttest1: 0.9135824\tbest: 0.9135857 (2287)\ttotal: 4m 58s\tremaining: 1m 32s\n",
      "2300:\ttest: 0.9275579\ttest1: 0.9136260\tbest: 0.9136260 (2300)\ttotal: 5m\tremaining: 1m 31s\n",
      "2310:\ttest: 0.9276759\ttest1: 0.9137312\tbest: 0.9137312 (2310)\ttotal: 5m 1s\tremaining: 1m 29s\n",
      "2320:\ttest: 0.9277507\ttest1: 0.9137998\tbest: 0.9137998 (2320)\ttotal: 5m 3s\tremaining: 1m 28s\n",
      "2330:\ttest: 0.9278124\ttest1: 0.9138441\tbest: 0.9138441 (2330)\ttotal: 5m 4s\tremaining: 1m 27s\n",
      "2340:\ttest: 0.9279322\ttest1: 0.9139188\tbest: 0.9139232 (2339)\ttotal: 5m 5s\tremaining: 1m 26s\n",
      "2350:\ttest: 0.9279815\ttest1: 0.9139864\tbest: 0.9139864 (2350)\ttotal: 5m 7s\tremaining: 1m 24s\n",
      "2360:\ttest: 0.9281182\ttest1: 0.9140352\tbest: 0.9140384 (2359)\ttotal: 5m 8s\tremaining: 1m 23s\n",
      "2370:\ttest: 0.9281630\ttest1: 0.9140891\tbest: 0.9140891 (2370)\ttotal: 5m 9s\tremaining: 1m 22s\n",
      "2380:\ttest: 0.9282810\ttest1: 0.9141410\tbest: 0.9141410 (2380)\ttotal: 5m 11s\tremaining: 1m 20s\n",
      "2390:\ttest: 0.9284181\ttest1: 0.9142391\tbest: 0.9142391 (2390)\ttotal: 5m 12s\tremaining: 1m 19s\n",
      "2400:\ttest: 0.9285270\ttest1: 0.9143206\tbest: 0.9143206 (2400)\ttotal: 5m 13s\tremaining: 1m 18s\n",
      "2410:\ttest: 0.9286243\ttest1: 0.9143925\tbest: 0.9143925 (2410)\ttotal: 5m 15s\tremaining: 1m 17s\n",
      "2420:\ttest: 0.9287074\ttest1: 0.9144453\tbest: 0.9144453 (2420)\ttotal: 5m 16s\tremaining: 1m 15s\n",
      "2430:\ttest: 0.9287893\ttest1: 0.9144833\tbest: 0.9144908 (2426)\ttotal: 5m 18s\tremaining: 1m 14s\n",
      "2440:\ttest: 0.9288796\ttest1: 0.9145854\tbest: 0.9145854 (2440)\ttotal: 5m 19s\tremaining: 1m 13s\n",
      "2450:\ttest: 0.9289412\ttest1: 0.9146227\tbest: 0.9146229 (2449)\ttotal: 5m 20s\tremaining: 1m 11s\n",
      "2460:\ttest: 0.9290510\ttest1: 0.9147259\tbest: 0.9147259 (2460)\ttotal: 5m 22s\tremaining: 1m 10s\n",
      "2470:\ttest: 0.9291542\ttest1: 0.9147945\tbest: 0.9147945 (2470)\ttotal: 5m 24s\tremaining: 1m 9s\n",
      "2480:\ttest: 0.9292672\ttest1: 0.9149111\tbest: 0.9149111 (2480)\ttotal: 5m 25s\tremaining: 1m 8s\n",
      "2490:\ttest: 0.9293099\ttest1: 0.9149688\tbest: 0.9149717 (2489)\ttotal: 5m 27s\tremaining: 1m 6s\n",
      "2500:\ttest: 0.9294623\ttest1: 0.9150942\tbest: 0.9150942 (2500)\ttotal: 5m 28s\tremaining: 1m 5s\n",
      "2510:\ttest: 0.9295562\ttest1: 0.9151501\tbest: 0.9151501 (2510)\ttotal: 5m 30s\tremaining: 1m 4s\n",
      "2520:\ttest: 0.9296405\ttest1: 0.9152158\tbest: 0.9152158 (2520)\ttotal: 5m 31s\tremaining: 1m 3s\n",
      "2530:\ttest: 0.9297806\ttest1: 0.9152996\tbest: 0.9152996 (2530)\ttotal: 5m 33s\tremaining: 1m 1s\n",
      "2540:\ttest: 0.9298900\ttest1: 0.9153582\tbest: 0.9153582 (2540)\ttotal: 5m 35s\tremaining: 1m\n",
      "2550:\ttest: 0.9300192\ttest1: 0.9154267\tbest: 0.9154267 (2550)\ttotal: 5m 36s\tremaining: 59.2s\n",
      "2560:\ttest: 0.9300889\ttest1: 0.9154941\tbest: 0.9154941 (2560)\ttotal: 5m 37s\tremaining: 57.9s\n",
      "2570:\ttest: 0.9301711\ttest1: 0.9155405\tbest: 0.9155405 (2570)\ttotal: 5m 39s\tremaining: 56.6s\n",
      "2580:\ttest: 0.9302821\ttest1: 0.9156062\tbest: 0.9156062 (2580)\ttotal: 5m 41s\tremaining: 55.4s\n",
      "2590:\ttest: 0.9303350\ttest1: 0.9156435\tbest: 0.9156439 (2589)\ttotal: 5m 42s\tremaining: 54.1s\n",
      "2600:\ttest: 0.9304541\ttest1: 0.9157247\tbest: 0.9157247 (2600)\ttotal: 5m 44s\tremaining: 52.9s\n",
      "2610:\ttest: 0.9305242\ttest1: 0.9157812\tbest: 0.9157812 (2610)\ttotal: 5m 46s\tremaining: 51.6s\n",
      "2620:\ttest: 0.9305963\ttest1: 0.9158430\tbest: 0.9158430 (2620)\ttotal: 5m 47s\tremaining: 50.3s\n",
      "2630:\ttest: 0.9307544\ttest1: 0.9159520\tbest: 0.9159520 (2630)\ttotal: 5m 49s\tremaining: 49s\n",
      "2640:\ttest: 0.9308414\ttest1: 0.9159805\tbest: 0.9159805 (2640)\ttotal: 5m 50s\tremaining: 47.7s\n",
      "2650:\ttest: 0.9309194\ttest1: 0.9160737\tbest: 0.9160737 (2650)\ttotal: 5m 52s\tremaining: 46.4s\n",
      "2660:\ttest: 0.9310586\ttest1: 0.9161622\tbest: 0.9161704 (2659)\ttotal: 5m 53s\tremaining: 45.1s\n",
      "2670:\ttest: 0.9312129\ttest1: 0.9162375\tbest: 0.9162375 (2670)\ttotal: 5m 55s\tremaining: 43.8s\n",
      "2680:\ttest: 0.9313340\ttest1: 0.9163311\tbest: 0.9163311 (2680)\ttotal: 5m 56s\tremaining: 42.4s\n",
      "2690:\ttest: 0.9314120\ttest1: 0.9163592\tbest: 0.9163664 (2688)\ttotal: 5m 58s\tremaining: 41.1s\n",
      "2700:\ttest: 0.9315506\ttest1: 0.9164328\tbest: 0.9164328 (2700)\ttotal: 5m 59s\tremaining: 39.8s\n",
      "2710:\ttest: 0.9316191\ttest1: 0.9165014\tbest: 0.9165014 (2710)\ttotal: 6m 1s\tremaining: 38.5s\n",
      "2720:\ttest: 0.9317207\ttest1: 0.9166145\tbest: 0.9166145 (2720)\ttotal: 6m 2s\tremaining: 37.2s\n",
      "2730:\ttest: 0.9318152\ttest1: 0.9166804\tbest: 0.9166804 (2730)\ttotal: 6m 4s\tremaining: 35.9s\n",
      "2740:\ttest: 0.9318989\ttest1: 0.9167550\tbest: 0.9167588 (2737)\ttotal: 6m 5s\tremaining: 34.5s\n",
      "2750:\ttest: 0.9319475\ttest1: 0.9167869\tbest: 0.9167869 (2750)\ttotal: 6m 6s\tremaining: 33.2s\n",
      "2760:\ttest: 0.9319908\ttest1: 0.9168376\tbest: 0.9168376 (2760)\ttotal: 6m 8s\tremaining: 31.9s\n",
      "2770:\ttest: 0.9321146\ttest1: 0.9169033\tbest: 0.9169061 (2769)\ttotal: 6m 9s\tremaining: 30.6s\n",
      "2780:\ttest: 0.9321556\ttest1: 0.9169253\tbest: 0.9169272 (2777)\ttotal: 6m 11s\tremaining: 29.3s\n",
      "2790:\ttest: 0.9322149\ttest1: 0.9169730\tbest: 0.9169730 (2790)\ttotal: 6m 12s\tremaining: 27.9s\n",
      "2800:\ttest: 0.9323093\ttest1: 0.9170522\tbest: 0.9170522 (2800)\ttotal: 6m 14s\tremaining: 26.6s\n",
      "2810:\ttest: 0.9323962\ttest1: 0.9171067\tbest: 0.9171067 (2810)\ttotal: 6m 16s\tremaining: 25.3s\n",
      "2820:\ttest: 0.9324432\ttest1: 0.9171283\tbest: 0.9171283 (2820)\ttotal: 6m 17s\tremaining: 24s\n",
      "2830:\ttest: 0.9324693\ttest1: 0.9171488\tbest: 0.9171488 (2830)\ttotal: 6m 18s\tremaining: 22.6s\n",
      "2840:\ttest: 0.9325334\ttest1: 0.9171559\tbest: 0.9171619 (2838)\ttotal: 6m 20s\tremaining: 21.3s\n",
      "2850:\ttest: 0.9325787\ttest1: 0.9171968\tbest: 0.9171968 (2850)\ttotal: 6m 22s\tremaining: 20s\n",
      "2860:\ttest: 0.9326427\ttest1: 0.9172516\tbest: 0.9172568 (2858)\ttotal: 6m 23s\tremaining: 18.7s\n",
      "2870:\ttest: 0.9327061\ttest1: 0.9173033\tbest: 0.9173033 (2870)\ttotal: 6m 25s\tremaining: 17.3s\n",
      "2880:\ttest: 0.9327334\ttest1: 0.9173481\tbest: 0.9173481 (2880)\ttotal: 6m 26s\tremaining: 16s\n",
      "2890:\ttest: 0.9327974\ttest1: 0.9173797\tbest: 0.9173797 (2890)\ttotal: 6m 28s\tremaining: 14.7s\n",
      "2900:\ttest: 0.9329050\ttest1: 0.9174903\tbest: 0.9174903 (2900)\ttotal: 6m 29s\tremaining: 13.3s\n",
      "2910:\ttest: 0.9330026\ttest1: 0.9175718\tbest: 0.9175718 (2910)\ttotal: 6m 31s\tremaining: 12s\n",
      "2920:\ttest: 0.9330485\ttest1: 0.9176011\tbest: 0.9176011 (2920)\ttotal: 6m 33s\tremaining: 10.6s\n",
      "2930:\ttest: 0.9331399\ttest1: 0.9176637\tbest: 0.9176640 (2929)\ttotal: 6m 34s\tremaining: 9.29s\n",
      "2940:\ttest: 0.9332135\ttest1: 0.9177326\tbest: 0.9177326 (2940)\ttotal: 6m 36s\tremaining: 7.96s\n",
      "2950:\ttest: 0.9332466\ttest1: 0.9177548\tbest: 0.9177580 (2948)\ttotal: 6m 37s\tremaining: 6.61s\n",
      "2960:\ttest: 0.9333213\ttest1: 0.9177885\tbest: 0.9177885 (2960)\ttotal: 6m 39s\tremaining: 5.26s\n",
      "2970:\ttest: 0.9334557\ttest1: 0.9179473\tbest: 0.9179473 (2970)\ttotal: 6m 41s\tremaining: 3.92s\n",
      "2980:\ttest: 0.9334884\ttest1: 0.9179598\tbest: 0.9179602 (2976)\ttotal: 6m 42s\tremaining: 2.56s\n",
      "2990:\ttest: 0.9335083\ttest1: 0.9179815\tbest: 0.9179815 (2990)\ttotal: 6m 43s\tremaining: 1.21s\n",
      "2999:\ttest: 0.9335992\ttest1: 0.9180601\tbest: 0.9180601 (2999)\ttotal: 6m 45s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9180601039\n",
      "bestIteration = 2999\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1ee8fe59790>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catb_model_with_cat = catb.CatBoostClassifier(**params_catb)\n",
    "catb_model_with_cat.fit(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 1000,\n",
    "    \"reg_lambda\": 50,\n",
    "    \"max_depth\": 10,\n",
    "    \"gamma\": 5,\n",
    "    \"nthread\": 4,\n",
    "    \"seed\": 29\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_without_cat = xgb.XGBClassifier(**params)\n",
    "xgb_model_without_cat.fit(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    num_boost_round=300,\n",
    "    early_stopping_rounds=20,\n",
    "    eval_metric=\"auc\",\n",
    "    verbose=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, для последующего обучения моделей используем следующие группы признаков:\n",
    "\n",
    "    1. num_features - для обучения моделей без категориальных признаков\n",
    "    2. num_feature_after_preproc - для обучения моделей с закодированными категориальными признаками\n",
    "    3. num_features + cat_features - для моделей, в которых есть встроенная обработка категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data[num_feature]\n",
    "y = train_data[target]\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
